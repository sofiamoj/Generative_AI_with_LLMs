# Lab 3 â€“ Detoxifying Summaries

This lab explores fine-tuning a generative model to reduce toxic or harmful content in automatically generated summaries.

## Objectives
- Analyze toxic content in text summaries.
- Fine-tune a generative model for toxicity mitigation.
- Compare original vs detoxified outputs.
- Evaluate effectiveness of toxicity reduction.

## Key Concepts
- Toxicity Detection and Mitigation
- Safety-Aware Fine-Tuning
- Controlled Text Generation
- Ethical AI in NLP

## Technologies
- Python, PyTorch
- Hugging Face Transformers
- PEFT, LoRA, TRL
- Datasets & Evaluate libraries

## Output
Detoxified summaries demonstrating safer, more ethical text generation.

